{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addc46e2",
   "metadata": {},
   "source": [
    "#### **Setup and Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b7b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color, feature, filters, exposure, measure, img_as_ubyte\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from skimage.transform import resize\n",
    "import pywt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56608d81",
   "metadata": {},
   "source": [
    "#### **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e32aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"E:/Rawan/Projects/Machine Learning/Project/Neurodegenerative-Diseases-Classifier/Data\"\n",
    "classes = [\"alzheimer\", \"parkinson\", \"normal\"]\n",
    "class_paths = {cls: os.path.join(base_path, cls) for cls in classes}\n",
    "\n",
    "# Function to load images\n",
    "def load_image(image_path):\n",
    "    # Load image\n",
    "    img = io.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale if it's RGB\n",
    "    if len(img.shape) > 2:\n",
    "        img = color.rgb2gray(img)\n",
    "    \n",
    "    # Ensure the image is in the correct format for feature extraction\n",
    "    img = img_as_ubyte(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dee69",
   "metadata": {},
   "source": [
    "#### **First-Order Statistical Features**\n",
    "\n",
    "First-order statistical features capture the distribution of pixel intensities in the MRI image. These features are important because they can reveal overall brightness, contrast, and intensity variations that may indicate tissue abnormalities.\n",
    "\n",
    "Key first-order features include:\n",
    "- **Mean**: Average intensity, which can indicate overall brain density\n",
    "- **Standard Deviation**: Variation in intensity, which can reflect tissue heterogeneity\n",
    "- **Skewness**: Asymmetry of the intensity distribution\n",
    "- **Kurtosis**: \"Peakedness\" of the intensity distribution\n",
    "- **Entropy**: Measure of randomness or unpredictability in pixel values\n",
    "\n",
    "These features are particularly useful for detecting general changes in brain tissue composition that occur in neurodegenerative diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "928c3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_order_features(image):\n",
    "    \"\"\"Extract first-order statistical features from an image.\"\"\"\n",
    "    # Flatten the image to get a 1D array of pixel values\n",
    "    pixels = image.flatten()\n",
    "    \n",
    "    # Calculate basic statistics\n",
    "    mean = np.mean(pixels)\n",
    "    std = np.std(pixels)\n",
    "    \n",
    "    # Calculate histogram\n",
    "    hist, _ = np.histogram(pixels, bins=256, range=(0, 255))\n",
    "    hist = hist / np.sum(hist)  # Normalize histogram\n",
    "    \n",
    "    # Calculate skewness\n",
    "    skewness = np.sum(((pixels - mean) / std) ** 3) / len(pixels) if std > 0 else 0\n",
    "    \n",
    "    # Calculate kurtosis\n",
    "    kurtosis = np.sum(((pixels - mean) / std) ** 4) / len(pixels) if std > 0 else 0\n",
    "    \n",
    "    # Calculate entropy\n",
    "    entropy = -np.sum(hist * np.log2(hist + 1e-10))\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    p10 = np.percentile(pixels, 10)\n",
    "    p25 = np.percentile(pixels, 25)\n",
    "    p75 = np.percentile(pixels, 75)\n",
    "    p90 = np.percentile(pixels, 90)\n",
    "    \n",
    "    # Calculate range\n",
    "    min_val = np.min(pixels)\n",
    "    max_val = np.max(pixels)\n",
    "    range_val = max_val - min_val\n",
    "    \n",
    "    # Return as dictionary\n",
    "    return {\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'skewness': skewness,\n",
    "        'kurtosis': kurtosis,\n",
    "        'entropy': entropy,\n",
    "        'p10': p10,\n",
    "        'p25': p25,\n",
    "        'p75': p75,\n",
    "        'p90': p90,\n",
    "        'min': min_val,\n",
    "        'max': max_val,\n",
    "        'range': range_val\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0367be",
   "metadata": {},
   "source": [
    "#### **Gray Level Co-occurrence Matrix (GLCM) Features**\n",
    "\n",
    "GLCM features are second-order statistical texture features that capture spatial relationships between pixels. These features are particularly valuable for neurodegenerative disease classification because they can detect subtle texture changes in brain tissue that may not be visible to the naked eye.\n",
    "\n",
    "The GLCM computes how often pairs of pixels with specific values occur in a specific spatial relationship. From this matrix, we can derive several important properties:\n",
    "\n",
    "- **Contrast**: Measures local variations in the GLCM\n",
    "- **Correlation**: Measures joint probability occurrence of specified pixel pairs\n",
    "- **Energy/ASM**: Provides the sum of squared elements in the GLCM\n",
    "- **Homogeneity**: Measures the closeness of the distribution of elements in the GLCM to its diagonal\n",
    "\n",
    "Research has shown that GLCM features can effectively differentiate between AD, PD, and normal brain tissues by capturing textural differences in regions like the hippocampus, thalamus, and cortical areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5f1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(image, distances=[1, 3], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    \"\"\"Extract GLCM texture features from an image.\"\"\"\n",
    "    # Make sure image is in uint8 format with values 0-255\n",
    "    if image.dtype != np.uint8:\n",
    "        image = img_as_ubyte(image)\n",
    "    \n",
    "    # Rescale to fewer gray levels (e.g., 0-15)\n",
    "    bins = 16  # Using 16 gray levels\n",
    "    max_val = np.max(image)\n",
    "    \n",
    "    # Ensure max value is less than bins\n",
    "    if max_val >= bins:\n",
    "        # Rescale image to 0-15\n",
    "        img_quantized = np.uint8(np.floor(image.astype(float) * (bins-1) / 255.0))\n",
    "    else:\n",
    "        img_quantized = image\n",
    "    \n",
    "    # Calculate GLCM\n",
    "    glcm = graycomatrix(img_quantized, distances=distances, angles=angles, \n",
    "                        levels=bins, symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GLCM properties\n",
    "    contrast = graycoprops(glcm, 'contrast').mean()\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity').mean()\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity').mean()\n",
    "    energy = graycoprops(glcm, 'energy').mean()\n",
    "    correlation = graycoprops(glcm, 'correlation').mean()\n",
    "    ASM = graycoprops(glcm, 'ASM').mean()\n",
    "    \n",
    "    # Return as dictionary\n",
    "    return {\n",
    "        'glcm_contrast': contrast,\n",
    "        'glcm_dissimilarity': dissimilarity,\n",
    "        'glcm_homogeneity': homogeneity,\n",
    "        'glcm_energy': energy,\n",
    "        'glcm_correlation': correlation,\n",
    "        'glcm_ASM': ASM\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b038012",
   "metadata": {},
   "source": [
    "#### **Local Binary Pattern (LBP) Features**\n",
    "\n",
    "Local Binary Pattern (LBP) is a powerful texture descriptor that characterizes the local structure of an image by comparing each pixel with its neighboring pixels. LBP is particularly useful for medical image analysis because:\n",
    "\n",
    "1. It's computationally efficient\n",
    "2. It's invariant to monotonic gray-level changes (which makes it robust to lighting variations)\n",
    "3. It can capture micro-patterns in the image\n",
    "\n",
    "For neurodegenerative disease classification, LBP can detect subtle texture changes in brain tissue that occur due to neurodegeneration. Studies have shown that LBP features can effectively differentiate between AD, PD, and normal brain tissues by capturing local texture patterns in regions like the hippocampus and cortical areas.\n",
    "\n",
    "We'll extract LBP histograms from the images, which will serve as a compact representation of the texture patterns present in the brain MRI scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0275db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_features(image, P=8, R=1):\n",
    "    \"\"\"Extract Local Binary Pattern features from an image.\"\"\"\n",
    "    # Calculate LBP\n",
    "    lbp = local_binary_pattern(image, P, R, method='uniform')\n",
    "    \n",
    "    # Calculate LBP histogram\n",
    "    n_bins = P + 2  # For uniform LBP\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    \n",
    "    # Create feature dictionary\n",
    "    lbp_features = {}\n",
    "    for i, h in enumerate(hist):\n",
    "        lbp_features[f'lbp_bin_{i}'] = h\n",
    "    \n",
    "    return lbp_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed7b29e",
   "metadata": {},
   "source": [
    "#### **Wavelet Features**\n",
    "\n",
    "Wavelet transform is a powerful technique for analyzing images at multiple scales and orientations. By decomposing an image into different frequency components, wavelets can capture both global and local texture information.\n",
    "\n",
    "For neurodegenerative disease classification, wavelet features are particularly valuable because:\n",
    "\n",
    "1. They can detect subtle changes in brain tissue texture at different scales\n",
    "2. They can capture directional information (horizontal, vertical, and diagonal details)\n",
    "3. They provide a compact representation of the image's texture\n",
    "\n",
    "Research has shown that wavelet features can effectively differentiate between AD, PD, and normal brain tissues by capturing multi-scale texture information in regions like the hippocampus, cortical areas, and subcortical structures.\n",
    "\n",
    "We'll use the Discrete Wavelet Transform (DWT) to decompose the image into approximation, horizontal, vertical, and diagonal coefficients, and then extract statistical features from these coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ece560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wavelet_features(image):\n",
    "    \"\"\"Extract wavelet features from an image.\"\"\"\n",
    "    # Apply wavelet transform\n",
    "    coeffs = pywt.dwt2(image, 'db1')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    \n",
    "    # Extract statistical features from each sub-band\n",
    "    wavelet_features = {}\n",
    "    \n",
    "    for name, coeff in zip(['LL', 'LH', 'HL', 'HH'], [LL, LH, HL, HH]):\n",
    "        # Calculate basic statistics\n",
    "        mean = np.mean(coeff)\n",
    "        std = np.std(coeff)\n",
    "        energy = np.sum(coeff**2) / coeff.size\n",
    "        entropy = -np.sum((coeff**2) * np.log2(coeff**2 + 1e-10)) / coeff.size\n",
    "        \n",
    "        wavelet_features[f'wavelet_{name}_mean'] = mean\n",
    "        wavelet_features[f'wavelet_{name}_std'] = std\n",
    "        wavelet_features[f'wavelet_{name}_energy'] = energy\n",
    "        wavelet_features[f'wavelet_{name}_entropy'] = entropy\n",
    "    \n",
    "    return wavelet_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ad0a1",
   "metadata": {},
   "source": [
    "#### **Edge and Gradient Features**\n",
    "\n",
    "Edge and gradient features capture important structural information in brain MRI scans by highlighting boundaries between different tissue types and anatomical structures. These features are valuable for neurodegenerative disease classification because:\n",
    "\n",
    "1. They can detect changes in brain structure boundaries that occur due to atrophy\n",
    "2. They can highlight subtle changes in tissue interfaces that may not be visible in the original image\n",
    "3. They provide information about the direction and magnitude of intensity changes\n",
    "\n",
    "For diseases like Alzheimer's and Parkinson's, changes in brain structure boundaries (such as ventricle enlargement or cortical thinning) are important diagnostic indicators. Edge and gradient features can help quantify these changes.\n",
    "\n",
    "We'll extract features like gradient magnitude statistics, Canny edge statistics, and Sobel filter responses to capture this structural information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001c94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edge_gradient_features(image):\n",
    "    \"\"\"Extract edge and gradient features from an image.\"\"\"\n",
    "    # Calculate gradient using Sobel operator\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Calculate gradient magnitude and direction\n",
    "    magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    direction = np.arctan2(sobely, sobelx)\n",
    "    \n",
    "    # Calculate Canny edges\n",
    "    edges = feature.canny(image, sigma=1)\n",
    "    \n",
    "    # Extract features\n",
    "    features = {\n",
    "        'gradient_mean': np.mean(magnitude),\n",
    "        'gradient_std': np.std(magnitude),\n",
    "        'gradient_energy': np.sum(magnitude**2) / magnitude.size,\n",
    "        'gradient_entropy': -np.sum((magnitude**2) * np.log2(magnitude**2 + 1e-10)) / magnitude.size,\n",
    "        'direction_mean': np.mean(direction),\n",
    "        'direction_std': np.std(direction),\n",
    "        'edge_density': np.sum(edges) / edges.size\n",
    "    }\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f00d5",
   "metadata": {},
   "source": [
    "#### **Gray Level Run Length Matrix (GLRLM) Features**\n",
    "\n",
    "Gray Level Run Length Matrix (GLRLM) is a texture analysis method that examines runs of pixels with the same gray level value in a specific direction. A run is defined as a set of consecutive pixels with the same gray level in a specific direction.\n",
    "\n",
    "GLRLM features are valuable for neurodegenerative disease classification because:\n",
    "\n",
    "1. They can capture patterns of homogeneous regions in the brain\n",
    "2. They provide information about the coarseness or fineness of texture\n",
    "3. They can detect subtle changes in tissue texture that occur due to neurodegeneration\n",
    "\n",
    "Studies have shown that GLRLM features can effectively differentiate between AD, PD, and normal brain tissues by capturing run-length based texture patterns in regions like the hippocampus, thalamus, and cortical areas.\n",
    "\n",
    "We'll extract features like Short Run Emphasis (SRE), Long Run Emphasis (LRE), and Run Length Non-uniformity (RLN) to capture this texture information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601eef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glrlm_features(image):\n",
    "    \"\"\"Extract Gray Level Run Length Matrix features from an image without using mahotas.\"\"\"\n",
    "    # Quantize the image to fewer gray levels\n",
    "    bins = 16\n",
    "    img_quantized = np.digitize(image, np.linspace(0, 255, bins+1)) - 1\n",
    "    \n",
    "    # Define directions for run length calculation\n",
    "    directions = [(1, 0),   # horizontal\n",
    "                  (0, 1),   # vertical\n",
    "                  (1, 1),   # diagonal\n",
    "                  (1, -1)]  # anti-diagonal\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Calculate run length features for each direction\n",
    "    for idx, (dx, dy) in enumerate(directions):\n",
    "        # Initialize counters\n",
    "        short_runs = 0\n",
    "        long_runs = 0\n",
    "        total_runs = 0\n",
    "        run_lengths = []\n",
    "        \n",
    "        # Process the image\n",
    "        rows, cols = img_quantized.shape\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                # Skip if we've already processed this pixel as part of a run\n",
    "                if img_quantized[i, j] == -1:\n",
    "                    continue\n",
    "                \n",
    "                # Start a new run\n",
    "                run_val = img_quantized[i, j]\n",
    "                run_length = 0\n",
    "                \n",
    "                # Follow the run in the current direction\n",
    "                x, y = j, i\n",
    "                while (0 <= x < cols and 0 <= y < rows and \n",
    "                       img_quantized[y, x] == run_val):\n",
    "                    # Mark as processed\n",
    "                    img_quantized[y, x] = -1\n",
    "                    run_length += 1\n",
    "                    \n",
    "                    # Move to next pixel in direction\n",
    "                    x += dx\n",
    "                    y += dy\n",
    "                \n",
    "                # Record the run\n",
    "                if run_length > 0:\n",
    "                    run_lengths.append(run_length)\n",
    "                    total_runs += 1\n",
    "                    \n",
    "                    # Classify as short or long run\n",
    "                    if run_length <= 2:\n",
    "                        short_runs += 1\n",
    "                    if run_length >= 4:\n",
    "                        long_runs += 1\n",
    "        \n",
    "        # Calculate features\n",
    "        if total_runs > 0:\n",
    "            # Short Run Emphasis (SRE)\n",
    "            features[f'glrlm_sre_dir{idx}'] = short_runs / total_runs\n",
    "            \n",
    "            # Long Run Emphasis (LRE)\n",
    "            features[f'glrlm_lre_dir{idx}'] = long_runs / total_runs\n",
    "            \n",
    "            # Run Length Non-uniformity (RLN)\n",
    "            if len(run_lengths) > 0:\n",
    "                features[f'glrlm_rln_dir{idx}'] = np.std(run_lengths) / np.mean(run_lengths) if np.mean(run_lengths) > 0 else 0\n",
    "            else:\n",
    "                features[f'glrlm_rln_dir{idx}'] = 0\n",
    "        else:\n",
    "            features[f'glrlm_sre_dir{idx}'] = 0\n",
    "            features[f'glrlm_lre_dir{idx}'] = 0\n",
    "            features[f'glrlm_rln_dir{idx}'] = 0\n",
    "    \n",
    "    # Calculate average features across all directions\n",
    "    features['glrlm_sre'] = np.mean([features[f'glrlm_sre_dir{i}'] for i in range(4)])\n",
    "    features['glrlm_lre'] = np.mean([features[f'glrlm_lre_dir{i}'] for i in range(4)])\n",
    "    features['glrlm_rln'] = np.mean([features[f'glrlm_rln_dir{i}'] for i in range(4)])\n",
    "    \n",
    "    # Remove direction-specific features to keep the feature set smaller\n",
    "    for i in range(4):\n",
    "        del features[f'glrlm_sre_dir{i}']\n",
    "        del features[f'glrlm_lre_dir{i}']\n",
    "        del features[f'glrlm_rln_dir{i}']\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e583c0f",
   "metadata": {},
   "source": [
    "#### **Feature Extraction Pipeline**\n",
    "\n",
    "Now we'll combine all the feature extraction methods into a single pipeline. This pipeline will:\n",
    "\n",
    "1. Load each image from the dataset\n",
    "2. Extract all the features we've defined\n",
    "3. Combine them into a single feature vector\n",
    "4. Save the results to a CSV file for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f20972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(image):\n",
    "    \"\"\"Extract all features from an image.\"\"\"\n",
    "    # Extract all features\n",
    "    features = {}\n",
    "    \n",
    "    # First-order statistical features\n",
    "    features.update(extract_first_order_features(image))\n",
    "    \n",
    "    # GLCM features\n",
    "    features.update(extract_glcm_features(image))\n",
    "    \n",
    "    # LBP features\n",
    "    features.update(extract_lbp_features(image))\n",
    "    \n",
    "    # Wavelet features\n",
    "    features.update(extract_wavelet_features(image))\n",
    "    \n",
    "    # Edge and gradient features\n",
    "    features.update(extract_edge_gradient_features(image))\n",
    "    \n",
    "    # GLRLM features\n",
    "    features.update(extract_glrlm_features(image))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def process_dataset():\n",
    "    \"\"\"Process all images in the dataset and extract features.\"\"\"\n",
    "    # Create a list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Process each class\n",
    "    for cls in classes:\n",
    "        class_path = class_paths[cls]\n",
    "        print(f\"Processing {cls} images...\")\n",
    "        \n",
    "        # Get all image files in the class folder\n",
    "        image_files = [f for f in os.listdir(class_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        # Process each image\n",
    "        for img_file in tqdm(image_files):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            try:\n",
    "                # Load image\n",
    "                image = load_image(img_path)\n",
    "                \n",
    "                # Extract features\n",
    "                features = extract_all_features(image)\n",
    "                \n",
    "                # Add class label and image filename\n",
    "                features['class'] = cls\n",
    "                features['filename'] = img_file\n",
    "                \n",
    "                # Add to results\n",
    "                results.append(features)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('brain_mri_features.csv', index=False)\n",
    "    print(f\"Features extracted and saved to brain_mri_features.csv\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fabd26",
   "metadata": {},
   "source": [
    "#### **Execution and Visualization**\n",
    "\n",
    "Finally, let's execute the feature extraction pipeline and visualize some of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the feature extraction pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = \"E:/Rawan/Projects/Machine Learning/Project/Neurodegenerative-Diseases-Classifier/Data\"\n",
    "    classes = [\"alzheimer\", \"parkinson\", \"normal\"]\n",
    "\n",
    "    # Process the dataset\n",
    "    features_df = process_dataset()\n",
    "    \n",
    "    # Display the first few rows of the features DataFrame\n",
    "    print(features_df.head())\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(\"\\nFeature statistics:\")\n",
    "    print(features_df.describe())\n",
    "    \n",
    "    # Count the number of samples per class\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(features_df['class'].value_counts())\n",
    "    \n",
    "    # Visualize some key features\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot histograms of some first-order features by class\n",
    "    for i, feature in enumerate(['mean', 'std', 'entropy']):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        for cls in classes:\n",
    "            plt.hist(features_df[features_df['class'] == cls][feature], alpha=0.5, label=cls, bins=20)\n",
    "        plt.title(f'Distribution of {feature}')\n",
    "        plt.legend()\n",
    "    \n",
    "    # Plot histograms of some GLCM features by class\n",
    "    for i, feature in enumerate(['glcm_contrast', 'glcm_homogeneity', 'glcm_energy']):\n",
    "        plt.subplot(2, 3, i+4)\n",
    "        for cls in classes:\n",
    "            plt.hist(features_df[features_df['class'] == cls][feature], alpha=0.5, label=cls, bins=20)\n",
    "        plt.title(f'Distribution of {feature}')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_distributions.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
